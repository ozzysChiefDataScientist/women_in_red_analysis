{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "import config as cfg\n",
    "import datetime\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective: Join together a data set listing articles nominated for deletion and a data set listing scraped Wikipedia articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../libraries/aws_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../libraries/general_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "   config_files = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_reader = boto3.resource('s3',\n",
    "                    region_name='us-east-1',\n",
    "                    aws_access_key_id=cfg.aws_reader['accessCode'],\n",
    "                    aws_secret_access_key=cfg.aws_reader['secretCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files = read_parquet_file(s3_reader, \n",
    "                                  config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                      config_files['ARTICLE_SCRAPE_DATES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>scrape_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Marvel_vs._DC\"_cards</td>\n",
       "      <td>[2023-04-30T00:00:00.000000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$teven_Cannon</td>\n",
       "      <td>[2023-02-22T00:00:00.000000, 2023-02-23T00:00:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-_(album)</td>\n",
       "      <td>[2023-03-02T00:00:00.000000, 2023-03-03T00:00:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              article_id                                        scrape_date\n",
       "0  \"Marvel_vs._DC\"_cards                       [2023-04-30T00:00:00.000000]\n",
       "1          $teven_Cannon  [2023-02-22T00:00:00.000000, 2023-02-23T00:00:...\n",
       "2              -_(album)  [2023-03-02T00:00:00.000000, 2023-03-03T00:00:..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_files[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "afd_metadata = read_parquet_file(s3_reader, \n",
    "                                  config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                      config_files['AFD_ARTICLE_NAMES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>found_person</th>\n",
       "      <th>num_entities</th>\n",
       "      <th>is_multiple_entity_types</th>\n",
       "      <th>file_name</th>\n",
       "      <th>discussion</th>\n",
       "      <th>afd_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margaret Louise Skourlis</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Featherston Drive Public School</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael D. Mehta</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            entity  found_person  num_entities  \\\n",
       "0         Margaret Louise Skourlis          True             1   \n",
       "1  Featherston Drive Public School         False             1   \n",
       "2                 Michael D. Mehta          True             1   \n",
       "\n",
       "   is_multiple_entity_types                                      file_name  \\\n",
       "0                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "1                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "2                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "\n",
       "                                          discussion afd_result  \n",
       "0  <div class=\"boilerplate afd vfd xfd-closed arc...     delete  \n",
       "1  <div class=\"boilerplate afd vfd xfd-closed arc...     delete  \n",
       "2  <div class=\"boilerplate afd vfd xfd-closed arc...     delete  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_metadata[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify articles about people vs other entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_to_process = afd_metadata[(afd_metadata['found_person']) & afd_metadata['num_entities']==1]\n",
    "initial_people_count = people_to_process.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract article_id, a unique identifier of the article name, from the Articles for Deletion Metadata so that we can join it onto the scraped_articles table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a_tags(html):\n",
    "    \"\"\"\n",
    "    Parses an HTML document and returns a list of all <a> tags found in the HTML.\n",
    "\n",
    "    Parameters:\n",
    "        html (str): The HTML document to parse.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries representing the <a> tags found in the HTML document. Each dictionary contains the attributes and values of the respective <a> tag.\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    href_tags = soup.find_all(\"a\")\n",
    "    return href_tags\n",
    "\n",
    "def get_href_tags(a_tags):\n",
    "    \"\"\"\n",
    "    Extracts the href attribute from a list of <a> tags and returns a list of valid non-empty href values.\n",
    "\n",
    "    Parameters:\n",
    "        a_tags (list): A list of dictionaries representing the <a> tags.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of valid non-empty href values extracted from the <a> tags.\n",
    "    \"\"\"\n",
    "    href_tags = [x.get('href') for x in a_tags]\n",
    "    href_tags = [x for x in href_tags if x is not None]\n",
    "    return href_tags\n",
    "\n",
    "def get_title_links(href_tags):\n",
    "    \"\"\"\n",
    "    Filters a list of href values to return only the links that are Wikipedia page titles.\n",
    "\n",
    "    Parameters:\n",
    "        href_tags (list): A list of href values.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique Wikipedia page title links derived from the href values.\n",
    "    \"\"\"\n",
    "    title_links =  [x for x in href_tags if 'https://en.wikipedia.org/w/index.php?title=' in x]\n",
    "    title_links =  [x for x in title_links if 'Special:' not in x]\n",
    "    title_links = list(set([x.split(\"&action\")[0] for x in title_links]))\n",
    "    return title_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "people_to_process['a_tags'] = people_to_process['discussion'].apply(lambda x: get_a_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "people_to_process['href_tags'] = people_to_process['a_tags'].apply(lambda x: get_href_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "people_to_process['title_links'] = people_to_process['href_tags'].apply(lambda x: get_title_links(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>found_person</th>\n",
       "      <th>num_entities</th>\n",
       "      <th>is_multiple_entity_types</th>\n",
       "      <th>file_name</th>\n",
       "      <th>discussion</th>\n",
       "      <th>afd_result</th>\n",
       "      <th>a_tags</th>\n",
       "      <th>href_tags</th>\n",
       "      <th>title_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Margaret Louise Skourlis</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[[talk page], [deletion review], [soft-delete]...</td>\n",
       "      <td>[/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael D. Mehta</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[[talk page], [deletion review], [PMC], [(talk...</td>\n",
       "      <td>[/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sangsadia Nirbachan 1991</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-01/2022_December_21.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>merge</td>\n",
       "      <td>[[talk page], [deletion review], [Military awa...</td>\n",
       "      <td>[/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     entity  found_person  num_entities  \\\n",
       "0  Margaret Louise Skourlis          True             1   \n",
       "2          Michael D. Mehta          True             1   \n",
       "6  Sangsadia Nirbachan 1991          True             1   \n",
       "\n",
       "   is_multiple_entity_types                                      file_name  \\\n",
       "0                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "2                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "6                     False  daily_afd_log/2023-01-01/2022_December_21.txt   \n",
       "\n",
       "                                          discussion afd_result  \\\n",
       "0  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "2  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "6  <div class=\"boilerplate afd vfd xfd-closed arc...      merge   \n",
       "\n",
       "                                              a_tags  \\\n",
       "0  [[talk page], [deletion review], [soft-delete]...   \n",
       "2  [[talk page], [deletion review], [PMC], [(talk...   \n",
       "6  [[talk page], [deletion review], [Military awa...   \n",
       "\n",
       "                                           href_tags  \\\n",
       "0  [/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...   \n",
       "2  [/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...   \n",
       "6  [/wiki/Help:Using_talk_pages, /wiki/Wikipedia:...   \n",
       "\n",
       "                                         title_links  \n",
       "0  [https://en.wikipedia.org/w/index.php?title=Ma...  \n",
       "2  [https://en.wikipedia.org/w/index.php?title=Mi...  \n",
       "6  [https://en.wikipedia.org/w/index.php?title=Bi...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_to_process[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess how well this logic work to obtain an article_id\n",
    "* Hope to find only 1 title link per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "people_to_process['len_title_links'] = people_to_process['title_links'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     874\n",
       "2      35\n",
       "3      11\n",
       "4       4\n",
       "37      1\n",
       "6       1\n",
       "7       1\n",
       "11      1\n",
       "0       1\n",
       "Name: len_title_links, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_to_process['len_title_links'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_to_process = people_to_process[people_to_process['len_title_links']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_to_process['article_id'] = people_to_process['title_links'].apply(lambda x: x[0].split(\"title=\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows: 55\n",
      "Dropped percent: 6.0\n"
     ]
    }
   ],
   "source": [
    "dropped_rows = initial_people_count - people_to_process.shape[0]\n",
    "dropped_rows_pct = dropped_rows / initial_people_count\n",
    "\n",
    "print(f'Dropped rows: {dropped_rows}')\n",
    "print(f'Dropped percent: {100*round(dropped_rows_pct,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_primary_key(people_to_process, ['article_id', 'file_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join two data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_files['article_id'] = scraped_files['article_id'].astype(str)\n",
    "people_to_process['article_id'] = people_to_process['article_id'].astype(str)\n",
    "articles_with_scraping_metadata = scraped_files.merge(people_to_process,\n",
    "                                                    on = ['article_id'],\n",
    "                                                     how=\"left\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_writer = boto3.client('s3',\n",
    "                    region_name='us-east-1',\n",
    "                    aws_access_key_id=cfg.aws_writer['accessCode'],\n",
    "                    aws_secret_access_key=cfg.aws_writer['secretCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '97NRH0P08N5RS2SJ',\n",
       "  'HostId': '4LqVzDndXgGNvVoc1SZRLflilqQOBoW3+PaPMwJZWnzzZkUE9xJuFXlDe3UsEQa8h1WcCo5s7EM=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '4LqVzDndXgGNvVoc1SZRLflilqQOBoW3+PaPMwJZWnzzZkUE9xJuFXlDe3UsEQa8h1WcCo5s7EM=',\n",
       "   'x-amz-request-id': '97NRH0P08N5RS2SJ',\n",
       "   'date': 'Sun, 28 May 2023 15:13:06 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"916a9d371aad898f194eeaea59ab46bc\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"916a9d371aad898f194eeaea59ab46bc\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_buffer = io.BytesIO()\n",
    "output_cols = ['article_id','scrape_date',\n",
    "               'entity','found_person','num_entities',\n",
    "               'is_multiple_entity_types','file_name','discussion',\n",
    "               'afd_result','title_links']\n",
    "articles_with_scraping_metadata[pd.isnull(articles_with_scraping_metadata['entity'])==False][output_cols].to_parquet(out_buffer, index=False)\n",
    "s3_writer.put_object( Bucket=config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                     Key=config_files['JOINED_ARTICLE_SCRAPE_DATES_AND_AFD_NAMES'], \n",
    "                     Body=out_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
