{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import boto3\n",
    "import config as cfg\n",
    "import datetime \n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../libraries/aws_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../libraries/general_utils.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as file:\n",
    "   config_files = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in base files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_reader = boto3.resource('s3',\n",
    "                    region_name='us-east-1',\n",
    "                    aws_access_key_id=cfg.aws_reader['accessCode'],\n",
    "                    aws_secret_access_key=cfg.aws_reader['secretCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_articles = read_parquet_file(s3_reader, \n",
    "                                  config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                      config_files['DELETED_VS_POPULATED_AFD_ARTICLES'])\n",
    "scraped_articles = scraped_articles[scraped_articles['is_kept']]\n",
    "test_primary_key(scraped_articles, ['article_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "afd_nomination_metadata = read_parquet_file(s3_reader, \n",
    "                                  config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                      config_files['JOINED_ARTICLE_SCRAPE_DATES_AND_AFD_NAMES'])\n",
    "test_primary_key(afd_nomination_metadata, ['article_id', 'file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>entity</th>\n",
       "      <th>found_person</th>\n",
       "      <th>num_entities</th>\n",
       "      <th>is_multiple_entity_types</th>\n",
       "      <th>file_name</th>\n",
       "      <th>discussion</th>\n",
       "      <th>afd_result</th>\n",
       "      <th>title_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022_Glen_Waverley_Suicide</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>2022 Glen Waverley Suicide</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-03/2022_December_23.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.S.D._Villabiagio</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>A.S.D. Villabiagio</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-03/2022_December_23.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>keep</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=A....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron_Kemmer</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>Aaron Kemmer</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-19/2023_January_8.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Aa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   article_id  \\\n",
       "0  2022_Glen_Waverley_Suicide   \n",
       "1          A.S.D._Villabiagio   \n",
       "2                Aaron_Kemmer   \n",
       "\n",
       "                                         scrape_date  \\\n",
       "0  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "1  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "2  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "\n",
       "                       entity  found_person  num_entities  \\\n",
       "0  2022 Glen Waverley Suicide          True           1.0   \n",
       "1          A.S.D. Villabiagio          True           1.0   \n",
       "2                Aaron Kemmer          True           1.0   \n",
       "\n",
       "   is_multiple_entity_types                                      file_name  \\\n",
       "0                     False  daily_afd_log/2023-01-03/2022_December_23.txt   \n",
       "1                     False  daily_afd_log/2023-01-03/2022_December_23.txt   \n",
       "2                     False    daily_afd_log/2023-01-19/2023_January_8.txt   \n",
       "\n",
       "                                          discussion afd_result  \\\n",
       "0  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "1  <div class=\"boilerplate afd vfd xfd-closed arc...       keep   \n",
       "2  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "\n",
       "                                         title_links  \n",
       "0  [https://en.wikipedia.org/w/index.php?title=20...  \n",
       "1  [https://en.wikipedia.org/w/index.php?title=A....  \n",
       "2  [https://en.wikipedia.org/w/index.php?title=Aa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_nomination_metadata[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(782, 10)\n",
      "(566, 13)\n"
     ]
    }
   ],
   "source": [
    "# limit scope to afd nominated articles where we found a populated wikipedia page\n",
    "print(afd_nomination_metadata.shape)\n",
    "afd_nomination_metadata = afd_nomination_metadata.merge(scraped_articles,\n",
    "                                                      on = ['article_id'])\n",
    "print(afd_nomination_metadata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_primary_key(afd_nomination_metadata, ['article_id', 'file_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>scrape_date</th>\n",
       "      <th>entity</th>\n",
       "      <th>found_person</th>\n",
       "      <th>num_entities</th>\n",
       "      <th>is_multiple_entity_types</th>\n",
       "      <th>file_name</th>\n",
       "      <th>discussion</th>\n",
       "      <th>afd_result</th>\n",
       "      <th>title_links</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>is_kept</th>\n",
       "      <th>scraped_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.S.D._Villabiagio</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>A.S.D. Villabiagio</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-03/2022_December_23.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>keep</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=A....</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>individual_afd_page_html/2023-01-01/A.S.D._Vil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron_Kemmer</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>Aaron Kemmer</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-19/2023_January_8.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Aa...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>individual_afd_page_html/2023-01-01/Aaron_Kemm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbas_Sajwani</td>\n",
       "      <td>[2023-01-01T00:00:00.000000, 2023-01-02T00:00:...</td>\n",
       "      <td>Abbas Sajwani</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>daily_afd_log/2023-01-07/2022_December_27.txt</td>\n",
       "      <td>&lt;div class=\"boilerplate afd vfd xfd-closed arc...</td>\n",
       "      <td>delete</td>\n",
       "      <td>[https://en.wikipedia.org/w/index.php?title=Ab...</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>True</td>\n",
       "      <td>individual_afd_page_html/2023-01-01/Abbas_Sajw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id                                        scrape_date  \\\n",
       "0  A.S.D._Villabiagio  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "1        Aaron_Kemmer  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "2       Abbas_Sajwani  [2023-01-01T00:00:00.000000, 2023-01-02T00:00:...   \n",
       "\n",
       "               entity  found_person  num_entities  is_multiple_entity_types  \\\n",
       "0  A.S.D. Villabiagio          True           1.0                     False   \n",
       "1        Aaron Kemmer          True           1.0                     False   \n",
       "2       Abbas Sajwani          True           1.0                     False   \n",
       "\n",
       "                                       file_name  \\\n",
       "0  daily_afd_log/2023-01-03/2022_December_23.txt   \n",
       "1    daily_afd_log/2023-01-19/2023_January_8.txt   \n",
       "2  daily_afd_log/2023-01-07/2022_December_27.txt   \n",
       "\n",
       "                                          discussion afd_result  \\\n",
       "0  <div class=\"boilerplate afd vfd xfd-closed arc...       keep   \n",
       "1  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "2  <div class=\"boilerplate afd vfd xfd-closed arc...     delete   \n",
       "\n",
       "                                         title_links scraped_date  is_kept  \\\n",
       "0  [https://en.wikipedia.org/w/index.php?title=A....   2023-01-01     True   \n",
       "1  [https://en.wikipedia.org/w/index.php?title=Aa...   2023-01-01     True   \n",
       "2  [https://en.wikipedia.org/w/index.php?title=Ab...   2023-01-01     True   \n",
       "\n",
       "                                        scraped_path  \n",
       "0  individual_afd_page_html/2023-01-01/A.S.D._Vil...  \n",
       "1  individual_afd_page_html/2023-01-01/Aaron_Kemm...  \n",
       "2  individual_afd_page_html/2023-01-01/Abbas_Sajw...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_nomination_metadata[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load scraped wikipedia articles for articles nominated for deletion, then extract article text vs reference links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "afd_text_extracts = pd.DataFrame()\n",
    "\n",
    "# using a for loop for now; it runs relatively fast (90 minutes across 600 records)\n",
    "for index, row in afd_nomination_metadata.iterrows():\n",
    "    \n",
    "    wiki_article = read_s3_file(s3_reader, config_files['RAW_BUCKET'], \n",
    "                   row['scraped_path'])\n",
    "    \n",
    "    article_soup = BeautifulSoup(wiki_article, \"html.parser\")\n",
    "    \n",
    "    # get the span tag with ID references, where reference links are stored\n",
    "    reference_tag = article_soup.find('span', id='References')\n",
    "    if reference_tag is not None:\n",
    "        has_references = True\n",
    "    else:\n",
    "        has_references = False\n",
    "    \n",
    "    if has_references:\n",
    "        article_text = wiki_article.split(str(reference_tag))[0] # article text before references\n",
    "        references_text = wiki_article.split(str(reference_tag))[1] # reference links\n",
    "        references_text = references_text.split(\"<h2>Navigation menu\")[0] # Remove wikipedia navigation links\n",
    "    else:\n",
    "        article_text = wiki_article\n",
    "        references_text = None\n",
    "        \n",
    "    temp_results = pd.DataFrame({\"article_id\": row['article_id'],\n",
    "                                 \"file_name\": row['file_name'],\n",
    "                                 \"scraped_path\": row['scraped_path'],\n",
    "                                 \"wiki_article\": wiki_article,\n",
    "                                \"articles_text\": article_text,\n",
    "                                 \"references_text\": references_text,\n",
    "                                 \"has_references\": has_references\n",
    "                                }, index=[0])\n",
    "    \n",
    "    if afd_text_extracts is None:\n",
    "        afd_text_extracts = temp_results\n",
    "    else:\n",
    "        afd_text_extracts = afd_text_extracts.append(temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.38166213035583\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(566, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_text_extracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     521\n",
       "False     45\n",
       "Name: has_references, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_text_extracts['has_references'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.920495\n",
       "False    0.079505\n",
       "Name: has_references, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afd_text_extracts['has_references'].value_counts() / afd_text_extracts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For articles that have references, extract individual reference links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    \"\"\"\n",
    "    Extracts the domain from a given URL.\n",
    "\n",
    "    Parameters:\n",
    "        url (str): The URL from which to extract the domain.\n",
    "\n",
    "    Returns:\n",
    "        str: The domain extracted from the URL.\n",
    "\n",
    "    Example Usage:\n",
    "        url = \"https://www.example.com/some-page\"\n",
    "        domain = extract_domain(url)\n",
    "        print(domain)  # Output: www.example.com\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc\n",
    "    return domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_link_results = pd.DataFrame()\n",
    "\n",
    "# using a for loop for now; it runs relatively fast (13 seconds on 500 records)\n",
    "for index, row in afd_text_extracts[afd_text_extracts['has_references']].iterrows():\n",
    "    \n",
    "    references_soup = BeautifulSoup(row['references_text'], \"html.parser\")\n",
    "    \n",
    "    # get <a> tags with links\n",
    "    a_tags = references_soup.find_all(\"a\")\n",
    "    \n",
    "    reference_links = pd.DataFrame({\"article_id\": row['article_id'],\n",
    "                                 \"file_name\": row['file_name'],\n",
    "                                 \"scraped_path\": row['scraped_path'],\n",
    "                                 \"references_text\": row['references_text'],\n",
    "                                \"a_tag\": a_tags})\n",
    "    \n",
    "    # Extract the URL link from the <a> tag\n",
    "    reference_links['href'] = reference_links['a_tag'].apply(lambda x: x.get('href'))\n",
    "    reference_links = reference_links[pd.isnull(reference_links['href'])==False]\n",
    "    \n",
    "    # some reference links start with \"web.archive.org/[date]/[ACTUAL_URL]\"\n",
    "    # because archive.org stores snapshots of web apges over time\n",
    "    # extract the actual URL\n",
    "    archive_org_pattern = r'https://web\\.archive\\.org/web/\\d+/(.*)'\n",
    "    reference_links['href_after_archive_org'] = reference_links['href'].apply(lambda x: re.sub(archive_org_pattern, r'\\1', x))\n",
    "    \n",
    "    reference_links['domain'] = reference_links['href_after_archive_org'].apply(lambda x: extract_domain(x))\n",
    "    \n",
    "     \n",
    "    wiki_keywords = ['/wiki/', 'wikipedia.org', 'wikimedia', 'mediawiki', 'creativecommons']\n",
    "    # Assign 'True' to 'is_wiki_page' if any keyword is found in 'href', otherwise 'False'\n",
    "    reference_links['is_wiki_page'] = reference_links['href'].apply(lambda x: any(keyword in x for keyword in wiki_keywords))\n",
    "   \n",
    "    if reference_link_results is None:\n",
    "        reference_link_results = reference_links\n",
    "    else:\n",
    "        reference_link_results = reference_link_results.append(reference_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.82423710823059\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>scraped_path</th>\n",
       "      <th>references_text</th>\n",
       "      <th>a_tag</th>\n",
       "      <th>href</th>\n",
       "      <th>href_after_archive_org</th>\n",
       "      <th>domain</th>\n",
       "      <th>is_wiki_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aaron_Kemmer</td>\n",
       "      <td>daily_afd_log/2023-01-19/2023_January_8.txt</td>\n",
       "      <td>individual_afd_page_html/2023-01-01/Aaron_Kemm...</td>\n",
       "      <td>&lt;span class=\"mw-editsection\"&gt;&lt;span class=\"mw-e...</td>\n",
       "      <td>[\"Made In Space - Aaron Kemmer\"]</td>\n",
       "      <td>https://web.archive.org/web/20160420005254/htt...</td>\n",
       "      <td>http://www.madeinspace.us/aaron-kemmer/</td>\n",
       "      <td>www.madeinspace.us</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Aaron_Kemmer</td>\n",
       "      <td>daily_afd_log/2023-01-19/2023_January_8.txt</td>\n",
       "      <td>individual_afd_page_html/2023-01-01/Aaron_Kemm...</td>\n",
       "      <td>&lt;span class=\"mw-editsection\"&gt;&lt;span class=\"mw-e...</td>\n",
       "      <td>[Archived]</td>\n",
       "      <td>https://web.archive.org/web/20180110124346/htt...</td>\n",
       "      <td>https://www.bloomberg.com/news/articles/2018-0...</td>\n",
       "      <td>www.bloomberg.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam_Cella</td>\n",
       "      <td>daily_afd_log/2023-01-21/2023_January_10.txt</td>\n",
       "      <td>individual_afd_page_html/2023-01-11/Adam_Cella...</td>\n",
       "      <td>&lt;span class=\"mw-editsection\"&gt;&lt;span class=\"mw-e...</td>\n",
       "      <td>[Archived]</td>\n",
       "      <td>https://web.archive.org/web/20151105092616/htt...</td>\n",
       "      <td>http://www.sherdog.com/fighter/Adam-Cella-69956</td>\n",
       "      <td>www.sherdog.com</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id                                     file_name  \\\n",
       "6   Aaron_Kemmer   daily_afd_log/2023-01-19/2023_January_8.txt   \n",
       "56  Aaron_Kemmer   daily_afd_log/2023-01-19/2023_January_8.txt   \n",
       "4     Adam_Cella  daily_afd_log/2023-01-21/2023_January_10.txt   \n",
       "\n",
       "                                         scraped_path  \\\n",
       "6   individual_afd_page_html/2023-01-01/Aaron_Kemm...   \n",
       "56  individual_afd_page_html/2023-01-01/Aaron_Kemm...   \n",
       "4   individual_afd_page_html/2023-01-11/Adam_Cella...   \n",
       "\n",
       "                                      references_text  \\\n",
       "6   <span class=\"mw-editsection\"><span class=\"mw-e...   \n",
       "56  <span class=\"mw-editsection\"><span class=\"mw-e...   \n",
       "4   <span class=\"mw-editsection\"><span class=\"mw-e...   \n",
       "\n",
       "                               a_tag  \\\n",
       "6   [\"Made In Space - Aaron Kemmer\"]   \n",
       "56                        [Archived]   \n",
       "4                         [Archived]   \n",
       "\n",
       "                                                 href  \\\n",
       "6   https://web.archive.org/web/20160420005254/htt...   \n",
       "56  https://web.archive.org/web/20180110124346/htt...   \n",
       "4   https://web.archive.org/web/20151105092616/htt...   \n",
       "\n",
       "                               href_after_archive_org              domain  \\\n",
       "6             http://www.madeinspace.us/aaron-kemmer/  www.madeinspace.us   \n",
       "56  https://www.bloomberg.com/news/articles/2018-0...   www.bloomberg.com   \n",
       "4     http://www.sherdog.com/fighter/Adam-Cella-69956     www.sherdog.com   \n",
       "\n",
       "    is_wiki_page  \n",
       "6          False  \n",
       "56         False  \n",
       "4          False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_link_results[reference_link_results['href'].str.contains(\"web.archive.org\")][0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>8406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cricketarchive.com</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>novelasyseries.univision.com</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.theguardian.com</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.worldcat.org</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>www.youtube.com</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>doi.org</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.uefa.com</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>news.bbc.co.uk</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.bbc.co.uk</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          index  domain\n",
       "0                                  8406\n",
       "1            cricketarchive.com     441\n",
       "2  novelasyseries.univision.com     209\n",
       "3           www.theguardian.com     140\n",
       "4              www.worldcat.org     134\n",
       "5               www.youtube.com      94\n",
       "6                       doi.org      73\n",
       "7                  www.uefa.com      70\n",
       "8                news.bbc.co.uk      68\n",
       "9                 www.bbc.co.uk      67"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_link_results[reference_link_results['is_wiki_page']==False]['domain'].value_counts().reset_index()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_writer = boto3.client('s3',\n",
    "                    region_name='us-east-1',\n",
    "                    aws_access_key_id=cfg.aws_writer['accessCode'],\n",
    "                    aws_secret_access_key=cfg.aws_writer['secretCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2NQBJTWT7HV3MD0Q',\n",
       "  'HostId': 'CY3OslgWFuyEavlQFpopO0C6+71n/mS761U8OLoD8QyAMYC24aigknk9vAlt2z/59t0E36rIpKluiTBGDt0cUw==',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'CY3OslgWFuyEavlQFpopO0C6+71n/mS761U8OLoD8QyAMYC24aigknk9vAlt2z/59t0E36rIpKluiTBGDt0cUw==',\n",
       "   'x-amz-request-id': '2NQBJTWT7HV3MD0Q',\n",
       "   'date': 'Wed, 31 May 2023 23:25:06 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"e10581aabb966717e89030f331ce3f85\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e10581aabb966717e89030f331ce3f85\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_buffer = io.BytesIO()\n",
    "afd_text_extracts.to_parquet(out_buffer, index=False)\n",
    "s3_writer.put_object( Bucket=config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                     Key=config_files['SCRAPED_ARTICLE_TEXT_AND_REFERENCE_TEXT'], \n",
    "                     Body=out_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'D74Y88Z4FMRHYV0H',\n",
       "  'HostId': 'psK7VU4dSMma06PRVdOZa2xxwd/6L8TTgHlncZL6G/Svna1KlDUQ6To1LJHqO5/jQud1rOzp6AY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'psK7VU4dSMma06PRVdOZa2xxwd/6L8TTgHlncZL6G/Svna1KlDUQ6To1LJHqO5/jQud1rOzp6AY=',\n",
       "   'x-amz-request-id': 'D74Y88Z4FMRHYV0H',\n",
       "   'date': 'Wed, 31 May 2023 23:26:12 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"e25fb657fe34d6dca96c4e0386bf8776\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e25fb657fe34d6dca96c4e0386bf8776\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_link_results = reference_link_results.drop('a_tag', axis=1) #drop column we don't need; we've extract relevant detail from it\n",
    "reference_link_results = reference_link_results[reference_link_results['domain']!=\"\"] # only keep meaningful results\n",
    "\n",
    "reference_link_results.to_parquet(out_buffer, index=False)\n",
    "s3_writer.put_object( Bucket=config_files['INTEREDIARY_OUTPUT_BUCKET'], \n",
    "                     Key=config_files['SCRAPED_REFERENCE_LINKS'], \n",
    "                     Body=out_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
